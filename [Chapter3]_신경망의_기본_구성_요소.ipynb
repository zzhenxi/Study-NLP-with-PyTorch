{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Chapter3] 신경망의 기본 구성 요소.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOaGKSpST64OLGC2K0bqCGv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzhenxi/study-NLP-with-PyTorch/blob/main/%5BChapter3%5D_%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98_%EA%B8%B0%EB%B3%B8_%EA%B5%AC%EC%84%B1_%EC%9A%94%EC%86%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "691oFCcroyYw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "'''\n",
        "note \n",
        "클래스 상속과 super에 대해서\n",
        "\n",
        "여기서 Perceptron이라는 class는 nn.Module을 상속 받았다. \n",
        "부모 : nn.Module (잠깐! torch.nn.module은 pytorch에서 모든 신경망 모델에 대한 베이스 class이며 신경망 모델을 다룰때 꼭! subclassing 해줘야 한다고 한다.)\n",
        "자식 : Perceptron\n",
        "\n",
        "만약 자식에게 __init__이 없는 경우라면, \n",
        "-> 부모인 nn.Module에서 생성자 함수가 생긴다. 따라서 부모의 생성자 함수의 내용을 출력 가능하다.\n",
        "\n",
        "하지만 여기에서는 자식의 __init__이 있다. 여기서 부모의 생성자 함수의 내용을 쓰려면? \n",
        "-> super().__init__(self)을 추가해주면 된다. \n",
        "\n",
        "그런데 여기에서는 super(Perceptron, self).__init__()라고 써주었다. 그 이유는? \n",
        "-> python 3. 부터 바뀐 방식 https://seeyoulater9468.tistory.com/155\n",
        "\n",
        "'''\n",
        "\n",
        "class Perceptron(nn.Module):\n",
        "  def __init__(self, input_dim):\n",
        "    super(Perceptron, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim, 1) # 이 Linear에서 w, b를 관리한다. \n",
        "  \n",
        "  def forward(self, x_in):\n",
        "    # x_in : 입력 데이터 텐서 (batch, num_features)\n",
        "    return torch.sigmoid(self.fc1(x_in)).squeeze() # (batch,)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 평균 제곱 오차 손실\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "mse_loss = nn.MSELoss()\n",
        "outputs = torch.randn(3,5, requires_grad=True)\n",
        "targets = torch.randn(3,5)\n",
        "loss = mse_loss(outputs, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VscfRfgqaJPx",
        "outputId": "2e9f6423-70fa-4489-b876-0318ac72c3b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.3589, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EGfprSvag4P",
        "outputId": "2ea35bf6-8c39-4218-f1f3-538bec4f8be5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.2099, -1.3108,  0.4623, -0.1381, -1.6445],\n",
              "        [ 0.8303,  0.2095, -1.1764, -0.1884,  1.7156],\n",
              "        [-0.5855,  0.3423, -0.3706,  0.5491,  0.0103]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o510dFGarQE",
        "outputId": "737c4934-91a3-4145-a658-b93eb9e6704a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1403, -1.2032, -1.4843,  0.3189,  0.6651],\n",
              "        [ 1.0640, -0.2253, -0.3024, -0.5579, -0.9045],\n",
              "        [-0.7953, -0.1583,  0.7137,  1.7073,  0.4726]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 크로스 엔트로피 손실 \n",
        "import torch \n",
        "import torch.nn as nn\n",
        "\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "outputs = torch.randn(3,5, requires_grad=True)\n",
        "targets = torch.tensor([1,0,3], dtype=torch.int64)\n",
        "loss = ce_loss(outputs, targets)\n",
        "print(loss)\n"
      ],
      "metadata": {
        "id": "kN-6bZ7PhSx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350390dc-dab2-46d8-b99b-8ad4f2fd798d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7372, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klteJT_IXtJH",
        "outputId": "dc37d4e8-0a08-4e78-d8dc-c37a6409dda3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3283, -0.0957,  0.6089,  0.2625, -0.9080],\n",
              "        [-0.2483,  0.5140, -0.4746, -0.8251, -0.0808],\n",
              "        [-0.7628, -0.0043,  1.1632,  0.4296,  0.9215]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7qoFtSWXxuU",
        "outputId": "68e6c0c7-3e36-4286-e733-728e632f8995"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "미니 배치 1 : [-0.3283, -0.0957,  0.6089,  0.2625, -0.9080]   \n",
        "미니 배치 2 : [-0.2483,  0.5140, -0.4746, -0.8251, -0.0808]   \n",
        "미니 배치 3 : [-0.7628, -0.0043,  1.1632,  0.4296,  0.9215]    \n",
        "미니 배치 1에 대한 타겟값 : 1   \n",
        "미니 배치 2에 대한 타겟값 : 0   \n",
        "미니 배치 3에 대한 타겟값 : 3   \n",
        "\n",
        "미니배치를 뜯어보면, [-0.3283, -0.0957,  0.6089,  0.2625, -0.9080] 은 각각 0, 1, 2, 3, 4에 대한 아웃풋이다. 여기서는 2번 값이 가장 크다. 그러니 소프트맥스를 하면 1에 대한 가장 큰 비율을 차지 할 것이다. "
      ],
      "metadata": {
        "id": "I1k-qIueouz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이진 크로스 엔트로피 손실\n",
        "\n",
        "bce_loss = nn.BCELoss()\n",
        "sigmoid = nn.Sigmoid()\n",
        "probabilities = sigmoid(torch.randn(4,1, requires_grad=True)) #sigmoid가 0-1사이의 범위로 압축해줌\n",
        "targets = torch.tensor([1,0,1,0], dtype=torch.float32).view(4,1)\n",
        "loss = bce_loss(probabilities, targets)"
      ],
      "metadata": {
        "id": "E6tv4hlzXzX_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5cbf6caBuaj",
        "outputId": "403b800c-e440-4f2d-82c2-894bff0748c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5504],\n",
              "        [0.7669],\n",
              "        [0.6396],\n",
              "        [0.4145]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-EHT7xaB4Zx",
        "outputId": "63431af7-cd6c-4c6b-a661-a8a1c70c42e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtSD-GHgCDoP",
        "outputId": "4e755346-d30e-4b8b-c6f7-495f8b662b15"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7590, grad_fn=<BinaryCrossEntropyBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim \n",
        "import torch.nn as nn\n",
        "\n",
        "input_dim = 2\n",
        "lr = 0.001\n",
        "\n",
        "perceptron = Perceptron(input_dim=input_dim)\n",
        "bce_loss = nn.BCELoss()\n",
        "optimizer = optim.Adam(params=perceptron.parameters(), lr=lr)\n"
      ],
      "metadata": {
        "id": "g9eUTwnaCKKY"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}